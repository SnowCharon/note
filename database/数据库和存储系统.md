# 数据存储容量

1. 位（bit）：最小的存储单位，通常表示二进制的0或1。
2. 字节（Byte）：由8个位组成，通常用于存储一个字符或一个小的整数。
3. 千字节（KB）：由1024个字节组成，常用于表示较小的文件或数据。
4. 兆字节（MB）：由1024个千字节组成，通常用于表示较大的文件或数据，如音乐、视频等。
5. 吉字节（GB）：由1024个兆字节组成，用于表示更大的文件或数据，如数据库、操作系统等。
6. 太字节（TB）：由1024个吉字节组成，通常用于表示大型的数据中心或云计算平台的存储容量。
7. 拍字节（PB）：由1024个太字节组成，用于表示更大规模的数据存储容量，如全球范围内的云计算数据中心。
8. 资字节（EB）：由1024个拍字节组成，用于表示极其巨大的数据存储容量，如全球范围内的超级计算机或数据存储中心。

# 数据库和存储系统

## 存储系统

### 数据流动

![ ](assets/image-20230212102431106.png)

### 特点

![image-20230212102630030](assets/image-20230212102630030.png)

![image-20230212102700454](assets/image-20230212102700454.png)

### 存储层级结构

![image-20230212102739453](assets/image-20230212102739453.png)

### 数据从产生到存储

![image-20230212103016704](assets/image-20230212103016704.png)

**缓存很重要**

### RAID技术

![image-20230212103315863](assets/image-20230212103315863.png)

## 数据库

### 关系型数据库

![image-20230212103539037](assets/image-20230212103539037.png)

1. 结构化数据友好
2. 支持事务
3. 支持复杂查询语句

### 非关系型数据库

![image-20230212103720798](assets/image-20230212103720798.png)

## 数据库 VS 经典存储

### 1.结构化数据管理

![image-20230212104135467](assets/image-20230212104135467.png)

很明显在结构化数据管理方面，关系型数据更胜一筹

### 2.事务能力

![image-20230212104159132](assets/image-20230212104159132.png)

### 3.复杂查询

![image-20230212104430339](assets/image-20230212104430339.png)



## 主流产品剖析

### 单机存储

释义：单个计算机节点上的软件存储系统，一般不涉及网络交互

#### 本地文件系统

![image-20230212105301898](assets/image-20230212105301898.png)

#### key-value存储

![image-20230212105323773](assets/image-20230212105323773.png)



### 分布式存储

释义：在单机存储基础上实现分布式协议，涉及大量网络交互

#### 分布式文件存储系统

![image-20230212115155836](assets/image-20230212115155836.png)



![image-20230212115552641](assets/image-20230212115552641.png)

Ceph是一种分布式存储系统，它具有高度的可伸缩性、可靠性和性能。Ceph使用对象存储、块存储和文件存储等多种存储方式，支持多种接口，包括S3、Swift、iSCSI、NFS等，可以满足不同应用场景的需求。

Ceph采用分布式架构，将数据分布在多个存储节点上，通过数据冗余和数据恢复机制确保数据的可靠性和完整性。Ceph还具有动态负载均衡和自动扩展等特性，可以根据实际需求自动调整存储节点的数量和容量，从而实现高可用性和高性能的存储系统。

Ceph的核心组件包括：

**RADOS（Reliable Autonomic Distributed Object Store）**：RADOS是Ceph的对象存储系统，它将数据分割成多个对象并存储在多个存储节点上，通过数据冗余和数据恢复机制确保数据的可靠性和完整性。

**Ceph OSD（Object Storage Device）**：Ceph OSD是Ceph的核心组件之一，它负责管理存储节点上的数据，包括数据的读写、复制、恢复等操作。

**Ceph MON（Monitor）**：Ceph MON是Ceph的监控组件，它负责监控整个Ceph集群的状态和性能，并提供元数据服务、负载均衡等功能。

**Ceph MDS（Metadata Server）**：Ceph MDS是Ceph的文件存储系统组件，它负责管理Ceph文件系统中的元数据，包括目录、文件、权限等信息。

Ceph可以满足不同规模和性能需求的存储场景，包括云存储、大数据存储、容器存储等，被广泛应用于云计算、人工智能、视频存储等领域

### 单机数据库

释义：单个计算机节点上的数据库系统——事务在单机内执行，也有可能通过网络实现分布式事务

 #### 关系型数据库

![image-20230212131346074](assets/image-20230212131346074.png)

![image-20230212131552755](assets/image-20230212131552755.png)

#### 关系型数据库

![image-20230212131821619](assets/image-20230212131821619.png)

![image-20230212132434137](assets/image-20230212132434137.png)

### 分布式数据库

池化技术：**将固定的多单机拼凑而成的Disk存储改为用内存池存储**
![image-20230212135315992](assets/image-20230212135315992.png)

1. 解决弹性问题

![image-20230212141703776](assets/image-20230212141703776.png)

2. 性价比问题

![image-20230212141743654](assets/image-20230212141743654.png)

## 新技术演进

![image-20230212142005146](assets/image-20230212142005146.png)

### SPDK

![image-20230212143124817](assets/image-20230212143124817.png)

SPDK（Storage Performance Development Kit）是由英特尔开源的一个高性能存储应用开发工具包。它为用户提供了一系列的API和工具，以帮助用户在Intel体系结构上开发高性能存储应用程序。SPDK的目标是提供一个高性能、低延迟的存储开发框架，使开发人员可以轻松地构建高效的存储系统和应用程序。

SPDK的特点包括：

1. 高性能：SPDK基于用户空间的设计，避免了操作系统内核和系统调用的开销，可以实现更低的延迟和更高的吞吐量。
2. 异步I/O：SPDK使用异步I/O技术，可以在保持CPU繁忙的同时，提供高效的I/O处理。
3. 硬件加速：SPDK支持利用硬件加速技术，如RDMA、NVMe、FPGA等，以进一步提高存储性能。
4. 易用性：SPDK提供了易用的API和工具，可以帮助开发人员快速构建高性能存储应用程序。

SPDK的应用范围广泛，包括云计算、虚拟化、大数据、数据库、存储系统等领域。它已被众多公司和组织采用，如英特尔、华为、百度、VMware等。

#### 避免从syscall

即免去每次都要从用户态切换到内核态才能操作系统

#### 轮询机制

轮询优于中断

#### Lock-free queue

Lock-free queue（无锁队列）是一种多线程编程中常用的数据结构，它可以实现高效的并发数据访问。与传统的基于锁的队列不同，无锁队列使用一些特殊的技术来避免线程之间的竞争和阻塞。

无锁队列通常采用**“比较并交换”（Compare and Swap，CAS）操作来实现并发操作。**CAS操作可以确保只有一个线程可以成功地修改共享变量，其他线程需要重新尝试修改直到成功为止，因此无锁队列可以避免锁的使用，从而提高并发性能和吞吐量。

**无锁队列通常包括一个生产者指针和一个消费者指针，生产者可以将元素插入到队列尾部，消费者可以从队列头部获取元素。由于没有锁的使用，无锁队列可能存在ABA问题（一个节点被删除后再次插入导致指针被改变），因此需要采取一些额外的措施来避免这种问题的发生，例如使用带有计数器的节点或者采用带有标记的指针等技术。**

无锁队列可以提高多线程编程的效率和可伸缩性，但也存在一些问题，例如实现难度较大、存在ABA问题、需要考虑内存管理等。因此，无锁队列需要谨慎使用，特别是在复杂的并发环境中

### AI & Storage

![image-20230212144016035](assets/image-20230212144016035.png)

### 高性能硬件

![image-20230212144409242](assets/image-20230212144409242.png)

#### RDMA网络

**RDMA（Remote Direct Memory Access——远程直接内存访问）网络是一种高性能、低延迟的网络技术，它可以让计算机系统直接访问远程计算机系统的内存，避免了传统网络中的数据复制和操作系统处理等开销，从而实现了非常高效的数据传输。**

RDMA网络通常使用专用的硬件设备，如网卡、交换机和传输协议等，可以实现非常低的传输延迟和非常高的吞吐量。RDMA网络可以使用多种协议，如InfiniBand、RoCE（RDMA over Converged Ethernet）和iWARP（Internet Wide Area RDMA Protocol）等，其中**InfiniBand**是应用最广泛的协议。

RDMA网络的应用范围非常广泛，包括高性能计算、云计算、大数据等领域。例如，在高性能计算中，RDMA网络可以用于快速传输大量的数据，从而提高计算效率；在云计算中，RDMA网络可以用于快速传输虚拟机间的数据，从而提高虚拟机的性能和响应时间；在大数据中，RDMA网络可以用于快速传输大量的数据，从而提高数据处理的效率和吞吐量。

需要注意的是，RDMA网络需要特殊的硬件设备和驱动程序支持，因此它的应用需要特定的环境和支持。但是，随着硬件和软件技术的不断发展，RDMA网络的应用越来越广泛，并且在高性能、低延迟的数据传输方面已经成为不可替代的技术。、

#### CPU,GPU&DPU

CPU（Central Processing Unit）、GPU（Graphics Processing Unit）和DPU（Data Processing Unit）是三种不同类型的处理器，它们各自有着不同的特点和应用场景。

CPU是一种通用处理器，它能够执行各种不同类型的计算任务，如算术运算、逻辑运算、控制流程等。CPU通常具有较高的时钟频率和较大的缓存容量，能够提供良好的单线程性能和通用性能，因此在日常计算机应用中得到了广泛应用，如文本处理、浏览器、办公软件等。

GPU是一种专用处理器，它通常用于图形处理和并行计算。GPU具有高度并行化的架构和大量的流处理器单元（Stream Processor Unit），能够在相同时间内执行大量的计算任务，如图形渲染、科学计算、深度学习等。GPU通常能够提供比CPU更高的并行性能和吞吐量，但相对于CPU在单线程性能上可能略有不足。

DPU是一种专门用于处理数据的处理器，它主要用于加速数据中心中的深度学习和人工智能应用。DPU通常集成了大量的计算单元和优化的深度学习算法，能够高效地执行深度学习任务，如卷积神经网络（CNN）、循环神经网络（RNN）等。相对于CPU和GPU，DPU在深度学习任务上能够提供更高的性能和效率，但在通用计算任务上可能不如CPU和GPU。

## 总结

![image-20230212144448246](assets/image-20230212144448246.png)

![image-20230214201544171](assets/image-20230214201544171.png)



# RDBMS

## 基本情况

RDBMS的一些主要特点包括：

1. **严格的数据一致性**：通过定义表之间的关系和约束条件，确保数据的完整性和一致性。
2. **高效的数据查询**：采用索引和缓存技术，能够快速地进行数据查询和检索。
3. **多用户的并发处理**：支持多个用户同时访问数据库，能够高效地处理并发请求。
4. **可扩展性和可靠性**：支持数据备份和恢复，能够处理大规模的数据存储和管理需求。
5. **标准化和通用性**：采用SQL语言作为操作接口，具有广泛的通用性和标准化特征。

### 事务ACID

![image-20230213135849116](assets/image-20230213135849116.png)

#### 高并发

#### 高可靠

## 数据库发展历史

### 网状型数据库

### 层级型数据库

### 关系型数据库

## 关键技术

### SQL一生

![image-20230213142449044](assets/image-20230213142449044.png)

### SQL引擎

#### Parser

**对SQL语句进行分析解构**

![image-20230213142623445](assets/image-20230213142623445.png)



#### Optimizer

**对SQL语句进行优化**

##### 基于规则的优化



![image-20230213143042575](assets/image-20230213143042575.png)

##### 基于代价的优化

![image-20230213143152640](assets/image-20230213143152640.png)

#### Executor

##### 火山模型

![image-20230213143534292](assets/image-20230213143534292.png)

##### 向量化模型

**如同buffer一样，一批一批返回数据**

![image-20230213143649056](assets/image-20230213143649056.png)

##### 编译执行

![image-20230213143836823](assets/image-20230213143836823.png)

### 存储引擎

#### InnoDB

![image-20230213144231151](assets/image-20230213144231151.png)

##### InnoDB

InnoDB是MySQL数据库的一个存储引擎，是MySQL的默认存储引擎之一。它提供了一系列高级功能，如**ACID事务支持、行级锁定、MVCC（Multi-Version Concurrency Control）等**，使其在大多数生产环境中被广泛使用。

InnoDB支持事务，可以保证数据的一致性和完整性。InnoDB采用行级锁定（Row-Level Locking）机制，使得不同的事务可以并发地访问同一个表的不同行，从而提高了并发性能。InnoDB还采用MVCC机制，可以提高并发读取的性能，避免不必要的锁定和等待。

除此之外，InnoDB还具有以下一些特点：

1. 支持外键约束：可以在表之间创建外键约束，保证数据的完整性。
2. 支持全文索引：可以在表的文本列上创建全文索引，从而提高全文搜索的性能。
3. 支持自适应哈希索引：可以根据查询模式动态地创建哈希索引，从而提高查询性能。
4. 支持热备份：可以在不停止MySQL服务器的情况下进行在线备份和恢复操作。
5. 支持存储过程和触发器：可以在数据库中编写存储过程和触发器，提高数据的处理和逻辑控制能力。

总之，InnoDB是一种性能优异、功能丰富、稳定可靠的存储引擎，是MySQL生态系统中的核心组件之一。

##### MVCC

MVCC是数据库管理系统中用于实现并发控制的一种技术。MVCC的全称为Multi-Version Concurrency Control，它通过在数据库中存储多个版本的数据来允许多个事务同时读取和修改同一数据，从而提高了并发性能和事务的吞吐量。

在MVCC中，每个事务都能看到其开始时间之前的数据版本，从而实现了数据的隔离性。当一个事务对数据进行修改时，数据库会创建一个新版本的数据，而不是在原有数据上直接修改，这保证了每个事务都在自己的版本上进行操作。这些版本的数据会存储在不同的地方，如Undo日志、Redo日志、回滚段等。

当一个事务要读取数据时，数据库会根据其开始时间来选择合适的数据版本。如果该版本已经被其他事务修改，则数据库会找到上一个可用的版本，以保证事务读取的是一致性数据。当一个事务提交后，其所修改的数据版本会成为其他事务的可见版本，这样其他事务就可以基于这个版本进行操作。

MVCC机制能够在保证数据隔离性的同时，提高并发性能，避免了一些不必要的锁等待和冲突。许多流行的数据库管理系统都采用了MVCC机制，如PostgreSQL、Oracle、MySQL等。

##### 行级锁定（Row-Level Locking）

行级锁定（Row-Level Locking）是一种并发控制技术，用于保证多个事务对数据库中的数据进行读写操作时的正确性和一致性。相比于表级锁定，行级锁定能够更细粒度地控制数据的访问，提高并发性能和系统的吞吐量。

在行级锁定中，数据库管理系统会为每个行数据分配一个独立的锁，当一个事务要对某一行进行修改时，需要先获取该行的锁。其他事务在此时无法修改该行数据，但可以读取该行数据。当事务完成对该行的修改后，会释放该行的锁，其他事务就可以基于新的数据版本进行操作。

行级锁定机制能够避免不必要的锁等待和冲突，提高了并发性能和系统的吞吐量。行级锁定常见于事务性数据库管理系统（如MySQL、PostgreSQL、Oracle等），并被广泛应用于高并发的Web应用、电子商务等场景。

#### Buffer Poll

![image-20230213144311574](assets/image-20230213144311574.png)

LRU算法

**长期不被使用的数据在未来用到的几率也不大，所以当新数据进来，优先把长期不使用的数据给替换掉——并非删除或覆盖，而是可能在缓存或内存中向后移动或者存到磁盘中去**

![image-20230213144829369](assets/image-20230213144829369.png)

#### Page

类似计算机操作系统的page

![image-20230213145029417](assets/image-20230213145029417.png)

#### B+

![image-20230213145107658](assets/image-20230213145107658.png)

### 事务引擎

#### Atomicity And Undo Log

![image-20230213145215848](assets/image-20230213145215848.png)

即通过逻辑日志记录，发生错误时回滚——逆向操作

#### Isolation And Lock

![image-20230213145402331](assets/image-20230213145402331.png)

#### Isolation And MVCC

![image-20230213145547883](assets/image-20230213145547883.png)

#### Durability And Read Log

![image-20230213145754619](assets/image-20230213145754619.png)



## 企业经验

### 大流量——Sharding

![image-20230213150227741](assets/image-20230213150227741.png)

Sharding是一种数据库水平分割的技术，也称为分片。它是将大型数据库分割成更小、更容易管理的部分，每个部分通常称为一个分片，每个分片可以存储不同的数据。

Sharding的目的是将数据库的负载分散到多个服务器上，提高数据库的处理能力和扩展性。在Sharding中，数据按照一定的规则分割成多个分片，每个分片可以被存储在不同的物理机器上，每个物理机器被称为一个Shard Server。当有查询请求时，数据库会自动将查询请求路由到相应的Shard Server上进行处理。这样，Sharding可以大大提高数据库的读写性能和容量。

Sharding的实现方式有很多种，其中比较常见的有基于范围、哈希、一致性哈希等算法。在基于范围的Sharding中，数据按照某个字段的值范围进行分割，例如按照订单ID进行范围分割；在哈希Sharding中，数据按照某个哈希函数的值进行分割，例如按照订单ID的哈希值进行分割；在一致性哈希Sharding中，每个节点都被映射到一个哈希环上，数据也按照哈希函数的值分割到环上，然后按照环上的节点分割为多个分片。

Sharding的实现需要考虑数据的一致性、可用性、容错性等问题，同时也需要考虑数据的备份、恢复、迁移等问题。因此，Sharding需要综合考虑很多因素，并需要有一定的技术实力和经验来实现和管理。

### 流量突增

#### 扩容

![image-20230213150528459](assets/image-20230213150528459.png)

#### 代理连接池

![image-20230213150644581](assets/image-20230213150644581.png)

### 稳定性&可靠性

#### 3AZ高可用

![image-20230213150851250](assets/image-20230213150851250.png)

3AZ高可用是指在云计算服务中，将应用程序或服务部署在至少三个不同的可用区（Availability Zone，AZ）中，以实现高可用性和容错性。可用区是指物理上独立的数据中心，每个可用区都有独立的供电、网络和硬件设施，可以避免单点故障和区域性灾害对服务的影响。

在3AZ高可用架构中，服务通常会在三个不同的可用区中运行至少三个实例，这些实例可以通过负载均衡器进行负载均衡和流量路由，从而保证服务的高可用性和容错性。如果其中一个可用区发生故障或不可用，负载均衡器会自动将流量路由到其他可用区中的实例，以确保服务的持续可用性。

采用3AZ高可用架构可以带来多种优势，包括：

1. 提高可用性：采用3AZ高可用架构可以将服务的可用性提高到99.99%以上，可以有效地避免单点故障和区域性灾害对服务的影响。
2. 提高容错性：采用3AZ高可用架构可以将服务的容错性提高到更高的水平，可以在故障发生时自动切换到其他可用区中的实例，保证服务的持续可用性。
3. 提高性能：采用3AZ高可用架构可以通过将服务部署在不同的可用区中，实现负载均衡和流量路由，从而提高服务的性能和吞吐量。
4. 提高安全性：采用3AZ高可用架构可以将数据和应用程序部署在多个地理位置中，从而降低数据泄露和应用程序被攻击的风险。

#### HA管理

![image-20230213150922321](assets/image-20230213150922321.png)

## 总结

![image-20230213151002073](assets/image-20230213151002073.png)

# TOS  对象存储实战

## 存储需求

![image-20230214201009719](assets/image-20230214201009719.png)

**存储需求：海量内存，易用，便宜**

## 对象存储

## 选择分布式存储

![image-20230214201623931](assets/image-20230214201623931.png)

![image-20230214201646970](assets/image-20230214201646970.png)

## 为什么选对象存储

![image-20230214201820269](assets/image-20230214201820269.png)

**总结：分布式存储的对象存储TOS赢麻了**

### 易用性——接口对比

#### HDFS

![image-20230214203244097](assets/image-20230214203244097.png)

HDFS（Hadoop Distributed File System）是一个分布式文件系统，是Apache Hadoop项目的核心组件之一。HDFS设计用于存储和处理大量数据集，能够处理PB级别的数据，并支持在大规模集群上运行的应用程序。

HDFS将大文件切分为多个数据块（block），并将这些数据块分布式地存储在集群中的多个节点上。每个数据块的默认大小为128MB，可以通过参数进行配置。HDFS的架构是一个主从式的结构，主节点称为NameNode，负责管理文件系统的命名空间、数据块映射以及负责数据块的分配和管理；从节点称为DataNode，负责存储和管理数据块。

HDFS提供了高容错性、高可靠性和高扩展性的特点，能够自动处理数据块的备份和数据块的失效。HDFS支持多种数据访问方式，包括Java API、命令行界面和web界面等。同时，HDFS也是Hadoop生态系统中许多其他工具和应用程序的重要基础，例如MapReduce、Hive、Pig等。

总的来说，HDFS是一个为海量数据存储和处理而设计的分布式文件系统，它具有高可靠性、高可用性、高扩展性、高效性等特点，并且是Hadoop生态系统中的核心组件之一。

#### 对象存储

![image-20230214203311313](assets/image-20230214203311313.png)

### 适用场景

![image-20230214203719160](assets/image-20230214203719160.png)

## 对象存储怎么用

### 申请Bucket

**需要在对象存储服务提供商的管理控制台申请……**

### Restful接口

![image-20230214204418018](assets/image-20230214204418018.png)

### MultiUpload接口

![image-20230214204817235](assets/image-20230214204817235.png)

### Listprefix接口

![image-20230214205014531](assets/image-20230214205014531.png)

## 开发一个对象存储

### 三层架构

![image-20230214215706035](assets/image-20230214215706035.png)

接入层：接入多个Bucket——解析http协议，权限，管理限速等

原信息层：存储对象元信息——对象大小，type,存储的位置等

存储引擎：存储对象的具体内容即Data

### 细化架构

![image-20230214220118397](assets/image-20230214220118397.png)

#### QPS

QPS是每秒查询率（Queries Per Second）的缩写，是衡量系统处理能力的一项重要指标。它表示系统在一秒钟内可以处理的查询（请求）的数量，即系统的处理能力。

QPS通常用于衡量Web服务器的性能，例如Apache、Nginx等。在这种情况下，每个查询通常是一个HTTP请求。QPS还可以用于衡量关系型数据库的性能，例如MySQL、PostgreSQL等。在这种情况下，每个查询通常是一个SQL查询语句。

需要注意的是，QPS不是衡量系统性能的唯一指标，还有其他指标如平均响应时间、并发请求数等。同时，QPS的计算可能会受到各种因素的影响，如网络带宽、硬件配置、系统负载等，因此需要综合考虑各种因素来评估系统的性能。

### 可扩展性解法——Partition(分而治之)

![image-20230214220736488](assets/image-20230214220736488.png)

![image-20230214221241845](assets/image-20230214221241845.png)

#### Hash和Range的优劣

Hash和Range是两种常用的数据分片技术。它们各有优缺点，适用于不同的应用场景。

**Hash分片的优点在于可以将数据均匀地分散在多个节点上，使得负载分布更均衡**，同时查询时也能够快速定位到数据所在节点。**缺点在于当需要添加或删除节点时，需要重新计算所有数据的哈希值，进行大规模的数据迁移**。

**Range分片的优点在于可以按照一定规则对数据进行排序和分片，使得数据更容易维护和管理。**同时也支持在不同节点间进行数据迁移，而不需要对所有数据进行重新分片。**缺点在于数据的分布可能不够均衡，部分节点的负载可能较大。**

因此，选择哪种分片方式取决于具体的应用场景和需求。如果对负载均衡和查询速度有较高要求，可以选择Hash分片；如果更关注数据的有序性和可维护性，则可以选择Range分片。

#### Paritition之间负载均衡

在数据分片的场景中，为了实现负载均衡，需要考虑两个方面：**数据的分片策略和数据的路由方式。**

数据分片策略：数据分片策略应该使得数据均匀地分散在各个分片中。一般来说，可以使用Hash、Range、Round-robin等策略进行分片，根据具体的业务需求和数据特点来选择合适的策略。

数据路由方式：当一个客户端请求到达系统时，需要根据请求的内容将其路由到正确的分片中。常用的路由方式包括：客户端直接发送到目标分片、通过代理中间件进行路由等。路由方式应该使得请求能够快速定位到目标分片，并保证各个分片的负载均衡。

需要注意的是，为了**实现真正的负载均衡，需要监控各个分片的负载状态，及时进行动态调整**。例如，当某个分片的负载过高时，可以将其部分数据迁移到其他分片中，以达到负载均衡的效果。

### 持久度解法——Replication

![image-20230214221420730](assets/image-20230214221420730.png)

#### Replication的拷贝方式有哪些

1. **基于日志复制**（log-based replication）：主节点将其操作日志记录下来，从节点按照顺序执行这些操作，以达到数据同步的目的。

2. **基于语句复制**（statement-based replication）：主节点将其执行的SQL语句发送给从节点，从节点按照相同的顺序执行这些SQL语句，以达到数据同步的目的。

3. **基于行复制**（row-based replication）：主节点将其数据行的修改记录发送给从节点，从节点根据这些记录来更新自己的数据行，以达到数据同步的目的。

4. **基于混合复制**（mixed-based replication）：将上述不同的复制方式进行组合，根据数据的类型和特点来选择最合适的复制方式。

#### Replication如何解决一致性问题

在一个复制系统中，任何修改都必须被同步到所有的副本，以确保所有节点上的数据保持一致。在修改提交之前，系统必须等待所有副本都接收并应用了这些修改。这种同步可以通过各种协议和算法来实现，例如：

1. **基于主节点的复制**（master-slave replication）：系统中只有一个主节点能够接收写请求，其他从节点只能接收读请求。主节点将修改操作记录到一个日志中，并将这些日志同步到从节点。从节点按顺序应用这些日志，以保证所有节点的数据一致。

2. **基于多主节点的复制**（multi-master replication）：系统中有多个主节点，每个主节点都能够接收写请求。当一个主节点接收到一个修改请求，它会将这个请求广播给其他节点，并等待其他节点的确认。当大多数节点都确认了这个修改请求，主节点就可以将其提交并广播给其他节点。

无论采用何种复制方式，一致性问题都需要在设计时考虑。例如，主节点宕机或网络故障可能会导致同步失败，从而导致数据不一致。因此，需要使用一些技术手段来检测和解决这些问题，例如使用心跳检测来检测节点是否可用，使用冲突解决算法来解决并发修改所导致的数据冲突等。

### 成本解决方法——EC

![image-20230214222241434](assets/image-20230214222241434.png)

#### EC编码算法有哪些

**EC（Erasure Coding）是一种数据编码和重建技术，常用于分布式存储和数据备份。它通过对数据进行分割、编码和冗余存储，提高了数据的可靠性和可恢复性。**

与传统的数据备份技术（如RAID）不同，EC通过对原始数据进行编码，生成更多的冗余数据，从而提高数据的恢复能力。在EC中，数据被分割成若干个数据块，并对这些数据块进行编码，生成多个校验块。这些校验块可以用于检测和恢复数据块的错误或丢失。通常情况下，EC编码的冗余数据比传统的数据备份技术更少，可以节省存储空间。

在分布式存储和网络传输中，EC（Erasure Coding，纠删码）被广泛应用于数据冗余和错误纠正。以下是一些常见的EC编码算法：

1. **Reed-Solomon编码**：Reed-Solomon编码是最常见的EC编码算法之一，它将数据分成一组数据块，对每个数据块进行编码以生成一组纠错编码块，这些编码块可以用来重建丢失或损坏的数据块。Reed-Solomon编码被广泛应用于RAID系统、对象存储和云存储等领域。

2. **Cauchy-Reed-Solomon编码**：Cauchy-Reed-Solomon编码是对Reed-Solomon编码的改进，它将数据块分成多个子块，每个子块与其他子块进行编码以生成一组纠错编码块。相对于Reed-Solomon编码，Cauchy-Reed-Solomon编码具有更高的纠错能力和更好的存储效率。

3. **Tornado编码**：Tornado编码是一种高效的EC编码算法，它将数据块分成多个子块，并使用一种矩阵编码方法生成一组纠错编码块。相对于传统的Reed-Solomon编码，Tornado编码可以提供更高的存储效率和更好的恢复速度。

3. **Fountain编码**：Fountain编码是一种随机线性编码算法，它将数据块分成一组数据符号，并使用一种随机编码方法生成一组纠错符号。Fountain编码具有很强的容错能力和高效的解码速度，被广泛应用于网络传输和无线通信等领域。

#### 多机房的EC如何实现

多机房的EC实现通常需要考虑两个问题：**数据冗余和数据访问**。

**对于数据冗余，通常需要在多个机房之间进行数据备份和冗余**。常用的方式是将数据分片存储在多个机房的不同节点上，并对每个数据分片进行EC编码，生成冗余数据块。这些冗余数据块可以存储在不同的机房中，以提高数据的可靠性和可恢复性。同时，需要确保在不同机房之间进行数据同步和备份，以保证数据的一致性和可用性。

**对于数据访问，通常需要考虑如何实现跨机房的数据访问**。在多机房环境中，数据访问的延迟和网络带宽可能会受到限制。因此，需要采用一些技术来优化数据访问性能，如**CDN、负载均衡、缓存等**。同时，需要对数据进行智能路由，使数据能够就近访问，以降低访问延迟。

总之，多机房的EC实现需要综合考虑数据冗余和数据访问两个方面的因素，需要选择合适的技术和策略来优化系统的性能和可靠性

### 成本解决方法——温冷转换

![image-20230214222559751](assets/image-20230214222559751.png)

### 架构细化

![image-20230214222656892](assets/image-20230214222656892.png)

### 存储需求量化

![image-20230214225740365](assets/image-20230214225740365.png)

#### SLA

SLA是Service Level Agreement的缩写，翻译成中文是“服务水平协议”。在存储领域中，SLA通常指存储服务提供商和用户之间的一种合同协议，用于明确存储服务的质量和性能指标。具体来说，SLA通常包括以下内容：

1. 可用性：指存储系统在一定时间内的可用性，通常以百分比表示，如99.99%。这意味着存储系统在一年中最多允许停机时间为52分钟。
2. 容量：指存储系统提供的存储容量，通常以GB或TB表示。
3. 吞吐量：指存储系统的读写吞吐量，通常以MB/s或GB/s表示。
4. IOPS：指存储系统的随机读写IOPS，通常表示每秒处理的IO请求数量。
5. 延迟：指存储系统的读写延迟，通常以毫秒或微秒表示。
6. 数据保护：指存储系统的数据备份和恢复机制，以及数据的可靠性和完整性保障。

通过SLA，用户可以了解存储服务提供商的服务质量和性能指标，并根据实际需求选择合适的存储服务。同时，存储服务提供商也需要严格履行SLA，确保存储服务的质量和性能，为用户提供稳定、高效、可靠的存储服务。

#### RPO

出现不可用后，数据不一致的时间

RPO指Recovery Point Objective，即恢复点目标。在灾难恢复和数据备份中，RPO是指可以接受的数据损失时间窗口，也就是系统中最近的可接受备份数据的时间。简单地说，**RPO是一个组织可以承受的数据丢失时间范围**。

例如，如果一个组织的RPO为4小时，则意味着在灾难发生时，该组织可以容忍最多4小时的数据丢失。这意味着**组织需要至少每4个小时进行一次数据备份，并将备份数据存储在远程位置，以防止单一数据中心或位置的全部损坏。**

RPO通常是通过数据备份策略来实现的。不同的应用程序和业务场景对RPO有不同的要求，需要根据实际情况进行调整。RPO通常是与RTO（恢复时间目标）一起使用，以确定系统可以接受的最大灾难恢复时间。

#### RTO

出现不可用后多久可以恢复

RTO指Recovery Time Objective，即恢复时间目标。在灾难恢复和数据备份中，RTO是指系统从发生灾难到完全恢复正常运行所需的时间。简单地说，RTO是一个组织可以接受的最长的系统停机时间。

例如，如果一个组织的RTO为8小时，则意味着在灾难发生时，该组织需要在8小时内将系统完全恢复到正常运行状态。为了达到这个目标，组织需要在实际灾难发生前考虑制定相应的灾难恢复计划、备份和恢复策略等措施，以最小化系统停机时间和数据丢失。

RTO通常与RPO（恢复点目标）一起使用，以确定系统在灾难发生时可以承受的最大数据丢失和停机时间。RTO可以帮助组织评估其业务连续性计划（BCP）和灾难恢复计划（DRP）的有效性，并确保系统能够在发生灾难时尽快恢复到正常运行状态。

### 高可用解法——拆分

![image-20230214225907909](assets/image-20230214225907909.png)

### 高可用解法——镜像灾备

**多镜像同步**

![image-20230214230112016](assets/image-20230214230112016.png)

![image-20230214230145063](assets/image-20230214230145063.png)

## 总结

![image-20230214230426381](assets/image-20230214230426381.png)



# 数据库项目背景

![image-20230215090645090](assets/image-20230215090645090.png)

